<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xiangxiang Cui</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://AbnerAi.github.io/"/>
  <updated>2024-08-30T03:37:29.549Z</updated>
  <id>https://AbnerAi.github.io/</id>
  
  <author>
    <name>Xiangxiang Cui</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Index</title>
    <link href="https://AbnerAi.github.io/2019/05/09/post/"/>
    <id>https://AbnerAi.github.io/2019/05/09/post/</id>
    <published>2019-05-09T05:39:34.000Z</published>
    <updated>2024-08-30T03:37:29.549Z</updated>
    
    <content type="html"><![CDATA[<h1 id="About-me"><a href="#About-me" class="headerlink" title="About me"></a>About me</h1><p>(Ph.D., 2022~Now) I am studying at Beijing  Normal University, State Key Laboratory of Cognitive Neuroscience and Learning. Advised by Prof. <a href="https://research.com/u/jing-sui" target="_blank" rel="noopener"><font color="blue"><u>Jing Sui</u></font></a>. <strong>Focus on the NeuroAI.</strong>  (M.E., 2019~2022) Advised by Prof. <a href="https://scholar.google.com/citations?user=S2FbC8oAAAAJ&amp;hl=en" target="_blank" rel="noopener"><font color="blue"><u>Zhongyu li</u></font></a>, Dr.<a href="https://scholar.google.com/citations?user=yl4PrOcAAAAJ&amp;hl=en/" target="_blank" rel="noopener"><font color="blue"><u>Bin Kong</u></font></a>.  <strong>Focus on AI for Medical Image Analysis</strong>. (B.E., 2014~2018) I majored in software engineering, and my graduation project focused on <strong>Embedded System Design</strong>. </p><table style="border-collapse: collapse;margin:auto"><tbody><tr style="border-collapse: separate; border-spacing:30em;"><td style="border-collapse: collapse; border: none;" width="40%"><b>Interests</b></td><td style="border-collapse: collapse; border: none;"><b>Education</b></td></tr><tr style="border-collapse: separate; border-spacing:30em;"><td style="border-collapse: collapse; border: none;">üß†NeuroAI<br>üåçMulti-modal<br>ü§ñÔ∏èDeep learning<br>üéØTrustworthy AI<br></td><td style="border-collapse: collapse; border: none;">üéìPh.D. in Beijing Normal University, 2022-Present<br><i style="margin-left:20px"><a href="https://brain.bnu.edu.cn/index.htm" target="_blank" style="text-decoration: none;">State Key Laboratory of Cognitive Neuroscience and Learning</a></i><br>üéìM.E. in Xi‚Äôan JiaoTong University, 2019-2022<br><i style="margin-left:20px"><a href="http://eie.xjtu.edu.cn/" target="_blank" style="text-decoration: none;">Faculty of Electronic and Information Engineering</a></i></td></tr></tbody></table><div style="background-color: #F8F8F8; color: #333; font-family: 'Times New Roman', Tahoma, Geneva, Verdana, sans-serif; padding: 10px 10px 10px 10px; border-radius: 4px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); line-height: 1.4; margin-top: 0;">I am dedicated to building <b>trustworthy Artificial General Intelligence (AGI)</b> models, with a focus on <b>AI theory, safety, and applications</b>. My research spans large language models (LLMs), NeuroAI, Knowledge graphs, Reinforcement learning, Computer vision, Multi-agent, and Multimodal learning. I also have an interest in applying these technologies to the scientific domain (AI4Science) to advance scientific discovery and technological innovation. If you are interested in the above topics, please contact me.</div><h1 id="Activities"><a href="#Activities" class="headerlink" title="Activities"></a>Activities</h1><ul><li>ü§î<strong>Studying</strong> LLM</li><li>üß™<strong>Coding</strong> on longitudinal analysis of depression based on large-scale dataset.</li><li>üß™<strong>Coding</strong> about Multimodal classification of psychiatric disorders.</li><li>‚úèÔ∏è<strong>Writing paper</strong> about uncertainty analysis in the field of radiotherapy with fellow medical physics majors.</li><li>‚úèÔ∏è<strong>Polishing paper</strong> about an academic paper on classification of psychiatric disorders. </li></ul><h1 id="News"><a href="#News" class="headerlink" title="News"></a>News</h1><ul><li>üéâ 2024/08 In collaboration with the Department of Oncology and Radiology of Peking University Third Hospital and other hospitals, we submitted a journal paper to the <strong>Medical physics 2024, <font color="purple">Accepted</font>.</strong> </li><li>‚åõÔ∏è <font color="blue">[Classification|fMRI] </font>2024/07 A paper on the classification of psychiatric disorders has been submitted to <strong>Medical Image Analysis 2024. Status: <font color="green">Under Review.</font></strong></li><li>üéâ 2024/04 A paper about eliminating site effects will be submitted to <strong>EMBC 2024, <font color="purple">CAAI B, Accepted</font>.</strong></li><li>‚åõÔ∏è <font color="blue">[Image Reconstruction] </font>2024/04 The paper on speckle reconstruction, which is a collaboration with the physics department, will be submitted to <strong>Optics letter, Status: <font color="green">Under Review.</font></strong></li><li>üéâ 2023/12 An abstract of neuroimage classification was submitted to <strong>OHBM2024, Poster presentation.</strong> </li><li>üéâ <font color="blue">[Patent|Radiotherapy] </font>2023/11 A <strong>patent</strong> for the application of artificial intelligence in the field of radiotherapy.</li></ul><h1 id="Selected-Publications"><a href="#Selected-Publications" class="headerlink" title="Selected Publications"></a>Selected Publications</h1><p>‚Äã       # Equal contributions</p><ul><li><font color="blue">[Classification|Site effect] </font><strong>Xiangxiang Cui</strong>#, Xueying Yang#, et al. ‚ÄúA StarGAN and Transformer-Based Hybrid Classification-Regression Model for Multi-institution VMAT Patient-Specific Quality Assurance.‚Äù In <strong>Medical Physics 2024 (JCR Q1, CAS Q2).</strong> </li><li><font color="blue">[Classification|Site effect] </font><strong>Xiangxiang Cui</strong>, Dongmei Zhi, Weizheng Yan, et al. ‚ÄúCGDM-GAN: An Adversarial Network Approach with Self-supervised Learning for Site Effect Removal. ‚Äú In <strong>EMBC 2024, CAAI B.</strong> </li><li><font color="blue">[Classification|fMRI] </font><strong>Xiangxiang Cui</strong>, et al. ‚ÄúMulti-Scale Analysis Framework Integrating Brain Functional Connectivity and Activity‚Äù In the <strong>Annual Meeting of the organization for Human Brain Mapping (OHBM) 2024.</strong> </li><li><font color="blue">[Classification|Site effect] </font><strong>Xiangxiang Cui</strong>, et al. ‚ÄúCGDM-GAN: An Adversarial Network Approach with Self-Supervised for Removing Site Effects‚Äù In the <strong>Annual Meeting of the organization for Human Brain Mapping (OHBM) 2023.</strong> </li><li><font color="blue">[Videos classification] </font><strong>Xiangxiang Cui</strong>, et al. ‚ÄúVariable-frame CNNLSTM for Breast Nodule Classification using Ultrasound Videos‚Äù <strong>Preprint 2023.</strong> </li><li><font color="blue">[Videos classification] </font>Yichen Wang, Zhongyu Li, <strong>Xiangxiang Cui</strong>, et al. ‚ÄúKey-frame Guided Network for Thyroid Nodule Recognition using Ultrasound Videos‚Äù In <strong>MICCAI 2022.</strong></li><li><font color="blue">[Model robustness|Segmentation|Adversarial attack] </font><strong>Xiangxiang Cui</strong>, et al. ‚ÄúDEAttack: A differential evolution based attack method for the robustness evaluation of medical image segmentation.‚Äù In <b>Neurocomputing 2021, IF:5.779</b>. </li></ul><h1 id="Research-experiences"><a href="#Research-experiences" class="headerlink" title="Research experiences"></a>Research experiences</h1><table style="border: none; border-collapse: collapse;" border="0"><!-- ultrasound classification --><tbody><tr style="border-collapse: separate; border-spacing:30em;border-bottom:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/ultra_video_classification.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Ultrasound Video Classification</b><br><ul><li>Feature extraction of multiple consecutive video frames based on CNN and LSTM.</li><li>The verification accuracy of video-based(Our) classification is higher than single-frame classification.</li></ul><i>This research was done in the Frontline Intelligent Technology Internship.</i></td></tr><!-- Head and neck segmentation --><tbody><tr style="border-collapse: separate; border-spacing:30em;border-bottom:1px #D3D3D3 solid"><td style="border-collapse: collapse;"> <img src="/2019/05/09/post/head_segmentation.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Head and Neck Segmentation</b><br><ul><li>Label Data Preparation: using regional growth and optical flow to generate pre-segmentation. The Label specialists manually revised pre-segmentation.</li><li>Deep Learning: using label data and 3D CNN to generate smooth segmentation results.</li></ul><i>This research was done in the ShenZhen Keya Medical Intership.</i></td></tr><!-- Coronary segmentation --><tbody><tr style="border-collapse: separate; border-spacing:30em;"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/Coronary_Seg.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Coronary Segmentation</b><br><ul><li>Using CNN to segment the aorta, analyse the aorta segmentation results and then adjust algorithmic to adapt to different hospital datasets.</li><li>Participating in the refinement of coronary segmentation, including vessel broken, vein removal.</li><li>Develop vessel segmentation results evaluation tools to improve iterative efficiency.</li></ul><i>This research was done in the ShenZhen Keya Medical Intership.</i></td></tr></tbody></tbody></tbody></table><h1 id="Engineering-experiences"><a href="#Engineering-experiences" class="headerlink" title="Engineering experiences"></a>Engineering experiences</h1><table style="border: none; border-collapse: collapse;" border="0"><!-- Slurm Server management --><tbody><tr style="border-collapse: separate; border-spacing:30em;"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/slurm.png" width="1500"></td><td style="border-collapse: collapse; border: none;"><b>Slurm Cluster Management(Centos)</b><br><ul><li>Slurm configuration fix.</li><li>Multi-user data privacy protection.</li><li>Software environment configuration.</li></ul><i>As a server administrator in the tutor lab of Beijing Normal University and CAS.</i></td></tr><!-- Server management --><tbody><tr style="border-collapse: separate; border-spacing:30em;border-top:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/servermanager.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Multi-User Server Management(Ubuntu)</b><br><ul><li>Deep learning, Docker environment configuration, system installation and problem fixes.</li><li>Multi-user data privacy protection. Each user has separate account access. Users are also grouped by project, and folders cannot be accessed between different groups.</li><li>Configure Remote Desktop Program so that every user can remotely access the remote desktop. Configure intranet penetration programs to ensure that the intranet can be accessed by external network programs under special circumstances.</li></ul><i>As a server administrator in the tutor lab of Xi‚Äôan Jiaotong University.</i></td></tr><!-- Robot --><tbody><tr style="border-collapse: separate; border-spacing:30em;border-top:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/dance.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Dance Robot</b><br><ul><li>The robot consists of rudder, and motion instructions are issued by the microcomputer system through a serial port.</li><li>For the coordination and smoothness of the dance, we carefully design the dance moves and use the data structure to coordinate the control action set.</li></ul></td></tr><!-- Web Compiler --><tr style="border-collapse: separate; border-spacing:30em;border-top:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/web_compiler.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Web Online Compiler</b><ul><li>The whole system is completed by using Html, Javascript, Php, Linux shell, Mysql.</li><li>Support languages: C, C++, C#, Java, Html, Javascript, Php.</li></ul><br></td></tr><!--Smart car --><tr style="border-collapse: separate; border-spacing:30em;border-top:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/car.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>The Embedded Car</b><ul><li>The whole system is completed by using microsystem STM32, Cortex-A8 and C language.</li><li>Using KNN to identify direction(turn to left or right) based on the Opencv library.</li><li>Using PID algorithm and sensor to control the travel stability of the embedded car.</li></ul><br></td></tr><!-- Union Search --><tr style="border-collapse: separate; border-spacing:30em;border-top:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/UnionSearch.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Union Search</b><ul><li>Based on JS, HTML to implement multiple search engine(such as: google/bing/baidu.) split-screen results display.</li><li>This program is simple, but very practical, once online for a while.</li></ul><br></td></tr><!-- The algorithm greedy snakes --><tr style="border-collapse: separate; border-spacing:30em;border-top:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/snakes.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Algorithm Greedy Snakes Game</b><ul><li>Design the game interface and develop intelligent snake algorithms using C++/CLR Library.</li><li>Based on the traditional greedy snake algorithms, our algorithm takes food as the target and takes artificially controlled snakes as an obstacle to make path planning. In the end, the winning rate of the algorithm snake exceeds 70%. </li></ul><br></td></tr><!-- Compus Today APP --><tr style="border-collapse: separate; border-spacing:30em;border-top:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/campustoday.png" width="800"></td><td style="border-collapse: collapse; border: none;"><b>Compus Today Android APP</b><ul><li>Realize the functions of BBS forum, news and information download, etc.</li><li>This project participated in the Innovation and Entrepreneurship Competition for Chinese College Students.</li></ul><br></td></tr><!-- Electroniclabels --><tr style="border-collapse: separate; border-spacing:30em;border-top:1px #D3D3D3 solid"><td style="border-collapse: collapse; border: none;"> <img src="/2019/05/09/post/Electroniclabels.gif" width="1000" style="height:150px"></td><td style="border-collapse: collapse; border: none;"><b>Electronic Labeling Systems</b><ul><li>The whole system is completed by using microsystem STM32, Wireless hardware module, Ajax, C, HTML, LWIP Network Protocol, ESP8266 module, HTTP Server.</li><li>Electronic labeling systems can be used in warehouses. The flow is sent from the web, via the wireless network module to the digital display, when the warehouse personnel completes the corresponding order, press the button of the electronic label, and finally the web will show that the task is complete.</li></ul><br></td></tr></tbody></tbody></tbody></table><hr><h1 id="Services"><a href="#Services" class="headerlink" title="Services"></a>Services</h1><p>Conference Reviewers: ICLR2025</p><div style="margin:auto;width:35%;height:35%"><script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=jZf-On0KI66JcrLeDTdDIh-kucVtCvtgHKEOd4Qio8Q&cl=ffffff&w=a"></script></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;About-me&quot;&gt;&lt;a href=&quot;#About-me&quot; class=&quot;headerlink&quot; title=&quot;About me&quot;&gt;&lt;/a&gt;About me&lt;/h1&gt;&lt;p&gt;(Ph.D., 2022~Now) I am studying at Beijing  No
      
    
    </summary>
    
    
  </entry>
  
</feed>
